{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import feather\n",
    "import os\n",
    "import torch\n",
    "\n",
    "\n",
    "# connect to db\n",
    "user = 'root'\n",
    "pswd = 'Curry5566'\n",
    "host = '127.0.0.1'\n",
    "port = '3306'\n",
    "db = 'transport'\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{pswd}@{host}:{port}/{db}?charset=utf8\")\n",
    "\n",
    "\n",
    "def getEndDate(startDate: str, days: int) -> str:\n",
    "    startDate += ' 00:00:00'\n",
    "    end = str((datetime.strptime(startDate, '%Y-%m-%d %H:%M:%S') + timedelta(days=days)).replace(microsecond=0))\n",
    "    return end\n",
    "\n",
    "def getRollingMean(startDate: str, endDate: str) -> pd.DataFrame:\n",
    "    \"\"\" Get the rolling mean from db\n",
    "        ```text\n",
    "        ---\n",
    "        @Params\n",
    "        startDate: The date for start, format='%Y-%m-%d'\n",
    "        endDate: The date for end, format='%Y-%m-%d'\n",
    "\n",
    "        ---\n",
    "        @Returns\n",
    "        DataFrame\n",
    "        ```\n",
    "    \"\"\"\n",
    "    sql  = \" SELECT \"\n",
    "    sql += \" \tSTAC.VDID, STAC.RoadName, STAC.`Start`, STAC.`End`, \"\n",
    "    sql += \" \tSTAC.RoadDirection, DYMC.Speed, DYMC.Occupancy, DYMC.Volume, \"\n",
    "    sql += \" \tSTAC.LocationMile, DYMC.DataCollectTime \"\n",
    "    sql += \" FROM ( \"\n",
    "    sql += \" \tSELECT \"\n",
    "    sql += \" \t\tVDSTC.id, VDSTC.VDID, ROAD.RoadName, SEC.`Start`, SEC.`End`, \"\n",
    "    sql += \" \t\tVDSTC.RoadDirection, VDSTC.LocationMile \"\n",
    "    sql += \" \tFROM vd_static_n5 VDSTC \"\n",
    "    sql += \" \tJOIN road_info ROAD ON VDSTC.RoadInfoID = ROAD.id \"\n",
    "    sql += \" \tJOIN section_info SEC ON ROAD.id = SEC.RoadInfoID \"\n",
    "    sql += \" \tAND VDSTC.LocationMile >= SEC.StartKM \"\n",
    "    sql += \" \tAND VDSTC.LocationMile <= SEC.EndKM \"\n",
    "    sql += \" \tWHERE VDSTC.Mainlane = 1 \"\n",
    "    sql += \" ) STAC JOIN ( \"\n",
    "    sql += \" \tSELECT \"\n",
    "    sql += \" \t\tVdStaticID, \"\n",
    "    sql += \" \t\tCASE \"\n",
    "    sql += \" \t\t\tWHEN MIN(Speed) = -99 THEN -99 \"\n",
    "    sql += \" \t\t\tELSE AVG(Speed) \"\n",
    "    sql += \" \t\tEND AS Speed,  \"\n",
    "    sql += \" \t\tCASE \"\n",
    "    sql += \" \t\t\tWHEN MIN(Occupancy) = -99 THEN -99 \"\n",
    "    sql += \" \t\t\tELSE AVG(Occupancy) \"\n",
    "    sql += \" \t\tEND AS Occupancy,  \"\n",
    "    sql += \" \t\tCASE \"\n",
    "    sql += \" \t\t\tWHEN MIN(Volume) = -99 THEN -99 \"\n",
    "    sql += \" \t\t\tELSE AVG(Volume) \"\n",
    "    sql += \" \t\tEND AS Volume, \"\n",
    "    sql += \" \t\tMAX(DataCollectTime) AS DataCollectTime, \"\n",
    "    sql += \" \t\t(UNIX_TIMESTAMP(DataCollectTime)-UNIX_TIMESTAMP(%(start)s)) DIV 300 \"\n",
    "    sql += \" \tFROM vd_dynamic_detail_n5_202301 \"\n",
    "    sql += \" \tWHERE id BETWEEN ( \"\n",
    "    sql += \" \t\tSELECT id FROM vd_dynamic_detail_n5_202301 \"\n",
    "    sql += \" \t\tWHERE DataCollectTime = %(start)s \"\n",
    "    sql += \" \t\tORDER BY id LIMIT 1 \"\n",
    "    sql += \" \t) AND ( \"\n",
    "    sql += \" \t\tSELECT id FROM vd_dynamic_detail_n5_202301 \"\n",
    "    sql += \" \t\tWHERE DataCollectTime < %(end)s \"\n",
    "    sql += \" \t\tORDER BY id DESC LIMIT 1 \"\n",
    "    sql += \" \t) \"\n",
    "    sql += \" \tGROUP BY VdStaticID, (UNIX_TIMESTAMP(DataCollectTime)-UNIX_TIMESTAMP(%(start)s)) DIV 300 \"\n",
    "    sql += \" ) DYMC ON STAC.id = DYMC.VdStaticID \"\n",
    "    sql += \" ORDER BY STAC.RoadDirection, STAC.LocationMile, DYMC.DataCollectTime; \"\n",
    "\n",
    "    df = pd.read_sql(sql, con=engine, params={'start': startDate, 'end': endDate})\n",
    "    engine.dispose()\n",
    "    return df.sort_values(by=['RoadDirection','DataCollectTime','LocationMile']).reset_index(drop=True)\n",
    "\n",
    "def getRollingMeanDaily(selectDate: str) -> pd.DataFrame:\n",
    "    sql  = \" SELECT \"\n",
    "    sql += \" \tSTAC.VDID, STAC.RoadName, STAC.`Start`, STAC.`End`, \"\n",
    "    sql += \" \tSTAC.RoadDirection, DYMC.Speed, DYMC.Occupancy, DYMC.Volume, \"\n",
    "    sql += \" \tSTAC.ActualLaneNum, STAC.LocationMile, DYMC.DataCollectTime \"\n",
    "    sql += \" FROM ( \"\n",
    "    sql += \" \tSELECT \"\n",
    "    sql += \" \t\tVDSTC.id, VDSTC.VDID, ROAD.RoadName, SEC.`Start`, SEC.`End`, \"\n",
    "    sql += \" \t\tVDSTC.ActualLaneNum, VDSTC.RoadDirection, VDSTC.LocationMile \"\n",
    "    sql += \" \tFROM fwy_n5.vd_static_2023 VDSTC \"\n",
    "    sql += \" \tJOIN transport.road_info ROAD ON VDSTC.RoadInfoID = ROAD.id \"\n",
    "    sql += \" \tJOIN transport.section_info SEC ON ROAD.id = SEC.RoadInfoID \"\n",
    "    sql += \" \tAND VDSTC.LocationMile >= SEC.StartKM \"\n",
    "    sql += \" \tAND VDSTC.LocationMile <= SEC.EndKM \"\n",
    "    sql += \" \tWHERE VDSTC.Mainlane = 1 \"\n",
    "    sql += \" ) STAC JOIN ( \"\n",
    "    sql += \" \tSELECT \"\n",
    "    sql += \" \t\tVdStaticID, \"\n",
    "    sql += \" \t\tCASE \"\n",
    "    sql += \" \t\t\tWHEN MIN(Speed) = -99 THEN -99 \"\n",
    "    sql += \" \t\t\tELSE AVG(Speed) \"\n",
    "    sql += \" \t\tEND AS Speed,  \"\n",
    "    sql += \" \t\tCASE \"\n",
    "    sql += \" \t\t\tWHEN MIN(Occupancy) = -99 THEN -99 \"\n",
    "    sql += \" \t\t\tELSE AVG(Occupancy) \"\n",
    "    sql += \" \t\tEND AS Occupancy,  \"\n",
    "    sql += \" \t\tCASE \"\n",
    "    sql += \" \t\t\tWHEN MIN(Volume) = -99 THEN -99 \"\n",
    "    sql += \" \t\t\tELSE AVG(Volume) \"\n",
    "    sql += \" \t\tEND AS Volume, \"\n",
    "    sql += \" \t\tMAX(DataCollectTime) AS DataCollectTime, \"\n",
    "    sql += \" \t\t(UNIX_TIMESTAMP(DataCollectTime)-UNIX_TIMESTAMP(%(selectDate)s)) DIV 300 \"\n",
    "    sql += \" \tFROM fwy_n5.vd_dynamic_detail_{} \".format(selectDate.replace('-',''))\n",
    "    sql += \" \tGROUP BY VdStaticID, (UNIX_TIMESTAMP(DataCollectTime)-UNIX_TIMESTAMP(%(selectDate)s)) DIV 300 \"\n",
    "    sql += \" ) DYMC ON STAC.id = DYMC.VdStaticID \"\n",
    "    sql += \" ORDER BY STAC.RoadDirection, STAC.LocationMile, DYMC.DataCollectTime; \"\n",
    "\n",
    "    df = pd.read_sql(sql, con=engine, params={'selectDate': selectDate})\n",
    "    engine.dispose()\n",
    "    return df.sort_values(by=['RoadDirection','DataCollectTime','LocationMile']).reset_index(drop=True)\n",
    "\n",
    "def groupVDs(df: pd.DataFrame, each: int) -> dict:\n",
    "    \"\"\" Get the dict of VD groups\n",
    "        ```text\n",
    "        ---\n",
    "        @Params\n",
    "        df: DataFrame which is referenced by.\n",
    "        each: The quantity of VDs would be considered as a group.\n",
    "\n",
    "        ---\n",
    "        @Returns\n",
    "        vdGroups: The keys are the VDs we focus on, and the values are the collections of VDs which are correlated corresponding to the keys.\n",
    "        ```\n",
    "    \"\"\"\n",
    "    vdGroups = {}\n",
    "    lb = each // 2\n",
    "    ub = each - (each // 2)\n",
    "    for vdid in df['VDID'].unique():\n",
    "        vdGroups.setdefault(f\"{vdid}\", [])\n",
    "    for no, vdid in enumerate(df['VDID'].unique()):\n",
    "        startIdx = max(no-lb, 0)\n",
    "        endIdx = min(no+ub, len(df['VDID'].unique())-1)\n",
    "        vdGroups[f\"{vdid}\"] += list(df['VDID'].unique()[startIdx:no]) + list(df['VDID'].unique()[no:endIdx])\n",
    "\n",
    "    delList = []\n",
    "    for k in vdGroups.keys():\n",
    "        if (len(vdGroups[k]) != each):\n",
    "            delList.append(k)\n",
    "    for k in delList:\n",
    "        del vdGroups[k]\n",
    "    \n",
    "    return vdGroups\n",
    "\n",
    "def genArrLists(df: pd.DataFrame, startDate: str, endDate: str, vdGroups: dict, groupKey: str,\n",
    "                each: int, timeWindow: int = 30) -> tuple:\n",
    "    \"\"\" # NOTE: This function has been deprecated.\n",
    "        Generate array lists for each traffic flow data (speed, volume, and occupancy)\n",
    "        ```text\n",
    "        ---\n",
    "        @Params\n",
    "        startDate: The date for start, format='%Y-%m-%d'\n",
    "        endDate: The date for end, format='%Y-%m-%d'\n",
    "        vdGroups: Can get it from groupVDs(),\n",
    "        groupKey: The key of vdGroups,\n",
    "        each: The quantity of VDs would be considered as a group,\n",
    "        timeWindow: The length of period we consider, and the default value is 30 (minutes).\n",
    "\n",
    "        ---\n",
    "        @Returns\n",
    "        speeds: list,\n",
    "        vols: list,\n",
    "        occs: list\n",
    "        ```\n",
    "    \"\"\"\n",
    "    freq5 = pd.date_range(startDate, endDate, freq='5min')\n",
    "    speeds, vols, occs = [], [], []\n",
    "    speed, vol, occ = [], [], []\n",
    "    for dtStart, dtEnd in zip(freq5[:-1], freq5[1:]):\n",
    "        print(f\"dtStart: {dtStart}\")\n",
    "        tmpDf = df.loc[(df['VDID'].isin(vdGroups[f\"{groupKey}\"])) &\\\n",
    "                       (df['DataCollectTime']>dtStart) &\\\n",
    "                       (df['DataCollectTime']<dtEnd)].sort_values(by='LocationMile')\n",
    "        if (len(speed) < timeWindow//5) and (len(vol) < timeWindow//5):\n",
    "            if (tmpDf[['Speed']].shape[0]>0) and (tmpDf[['Volume']].shape[0]>0):\n",
    "                speed.append(tmpDf[['Speed']].to_numpy())\n",
    "                vol.append(tmpDf[['Volume']].to_numpy())\n",
    "                occ.append(tmpDf[['Occupancy']].to_numpy())\n",
    "            else:\n",
    "                speed.append(np.array([[-99.] for _ in range(each)]))\n",
    "                vol.append(np.array([[-99.] for _ in range(each)]))\n",
    "                occ.append(np.array([[-99.] for _ in range(each)]))\n",
    "        else:\n",
    "            speeds.append(np.concatenate(speed, axis=1))\n",
    "            vols.append(np.concatenate(vol, axis=1))\n",
    "            occs.append(np.concatenate(occ, axis=1))\n",
    "            \n",
    "            speed.clear()\n",
    "            vol.clear()\n",
    "            occ.clear()\n",
    "    \n",
    "    return speeds, vols, occs\n",
    "\n",
    "def genSamples(df: pd.DataFrame, vdGroups: dict, groupKey: str, each: int, timeWindow: int = 30) -> tuple:\n",
    "    \"\"\" Generate samples for each traffic data (speed, volume, and occupancy)\n",
    "        ```text\n",
    "        ---\n",
    "        @Params\n",
    "        df: \n",
    "        vdGroups: The outpur of groupVDs(),\n",
    "        groupKey: The key of vdGroups,\n",
    "        each: The quantity of VDs would be considered as a group,\n",
    "        timeWindow: The length of period we consider, and the default value is 30 (minutes).\n",
    "\n",
    "        ---\n",
    "        @Returns\n",
    "        speeds: list with each item as a tuple, all of them are represented (X,y).\n",
    "        vols: list with each item as a tuple, all of them are represented (X,y).\n",
    "        occs: list with each item as a tuple, all of them are represented (X,y).\n",
    "        ```\n",
    "    \"\"\"\n",
    "    speeds, vols, occs = [], [], []\n",
    "    tmpDf = df.loc[(df['VDID'].isin(vdGroups[f\"{groupKey}\"]))].sort_values(by=['LocationMile', 'DataCollectTime'])\n",
    "\n",
    "    indices = [x for x in range(0, tmpDf.shape[0]+1, tmpDf.shape[0]//each)]\n",
    "    speedMatx = np.zeros((each, tmpDf.shape[0]//each))\n",
    "    volMatx = np.zeros((each, tmpDf.shape[0]//each))\n",
    "    occMatx = np.zeros((each, tmpDf.shape[0]//each))\n",
    "    for i, j, k in zip(range(each), indices[:-1], indices[1:]):\n",
    "        speedMatx[i] += tmpDf.iloc[j:k,:]['Speed'].to_numpy()\n",
    "        volMatx[i] += tmpDf.iloc[j:k,:]['Volume'].to_numpy()\n",
    "        occMatx[i] += tmpDf.iloc[j:k,:]['Occupancy'].to_numpy()\n",
    "\n",
    "    sliceLen = int((timeWindow / 5) + 1)\n",
    "    for x in range(speedMatx.shape[1]//sliceLen*sliceLen-(sliceLen-1)):\n",
    "        speeds.append((speedMatx[:,x:x+sliceLen][:,:-1], speedMatx[:,x:x+sliceLen][:,[-1]]))\n",
    "        vols.append((volMatx[:,x:x+sliceLen][:,:-1], volMatx[:,x:x+sliceLen][:,[-1]]))\n",
    "        occs.append((occMatx[:,x:x+sliceLen][:,:-1], occMatx[:,x:x+sliceLen][:,[-1]]))\n",
    "    \n",
    "    return speeds, vols, occs\n",
    "\n",
    "def genTensors(speeds: list, vols: list) -> list:\n",
    "    \"\"\" Generate torch.Tensors.\n",
    "        The sizes of the tensors are `[batch, 2, each, 6]`, and `each` depends on how many VDs regarded as a group.\n",
    "    \"\"\"\n",
    "    dataCollection = []\n",
    "    for s, v in zip(speeds, vols):\n",
    "        s = torch.tensor(s, dtype=torch.float).unsqueeze(0).unsqueeze(0)\n",
    "        v = torch.tensor(v, dtype=torch.float).unsqueeze(0).unsqueeze(0)\n",
    "        dataCollection.append(torch.concat([s, v], dim=1))\n",
    "    return dataCollection\n",
    "\n",
    "def train_test_split(speedCollection, volCollection, train_size=None, test_size=None, random_number=42):\n",
    "    np.random.seed(random_number)\n",
    "    if train_size:\n",
    "        trainDataIdx = np.random.choice(\n",
    "            len(speedCollection),\n",
    "            int(train_size * len(speedCollection)),\n",
    "            replace=False\n",
    "        )\n",
    "        testDataIdx = set([i for i in range(len(speedCollection))]) -\\\n",
    "                      set(trainDataIdx)\n",
    "    \n",
    "    elif test_size:\n",
    "        testDataIdx = np.random.choice(\n",
    "            len(speedCollection),\n",
    "            int(test_size * len(speedCollection)),\n",
    "            replace=False\n",
    "        )\n",
    "        trainDataIdx = set([i for i in range(len(speedCollection))]) -\\\n",
    "                       set(testDataIdx)\n",
    "        \n",
    "    trainSpeed = list(pd.Series(speedCollection)[list(trainDataIdx)])\n",
    "    trainVol = list(pd.Series(volCollection)[list(trainDataIdx)])\n",
    "    testSpeed = list(pd.Series(speedCollection)[list(testDataIdx)])\n",
    "    testVol = list(pd.Series(volCollection)[list(testDataIdx)])\n",
    "\n",
    "    return trainSpeed, trainVol, testSpeed, testVol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 取得一年份資料\n",
    "# firstDate = list(map(lambda x: datetime.strftime(x, '%Y-%m-%d'), list(pd.date_range('2023-01-01', '2023-12-31', freq='MS'))))\n",
    "# lastDate = list(map(lambda x: datetime.strftime(x, '%Y-%m-%d'), list(pd.date_range('2023-01-01', '2023-12-31', freq='ME'))))\n",
    "# for first, last in zip(firstDate, lastDate):\n",
    "#     dataframes = []\n",
    "#     dateList = list(map(lambda x: datetime.strftime(x, '%Y-%m-%d'), list(pd.date_range(first, last))))\n",
    "#     for date in dateList:\n",
    "#         print(date)\n",
    "#         dataframes.append(getRollingMeanDaily(date))\n",
    "#     dataframes = pd.concat(dataframes).reset_index(drop=True)\n",
    "#     display(dataframes)\n",
    "#     feather.write_dataframe(dataframes, dest=f\"./nfb2023/{date[:7].replace('-','')}.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthlyStarts = list(map(lambda x: datetime.strftime(x, '%Y-%m-%d'), list(pd.date_range('2023-02-01', '2023-02-28', freq='MS'))))\n",
    "monthlyEnds = list(map(lambda x: datetime.strftime(x, '%Y-%m-%d'), list(pd.date_range('2023-02-01', '2023-02-28', freq='ME'))))\n",
    "\n",
    "for start, end in zip(monthlyStarts, monthlyEnds):\n",
    "    dataframes = []\n",
    "    dateList = list(map(lambda x: datetime.strftime(x, '%Y-%m-%d'), list(pd.date_range(start, end))))\n",
    "    print(start[:7].replace('-',''))\n",
    "    for date in dateList:\n",
    "        print(date)\n",
    "        dataframes.append(getRollingMeanDaily(date))\n",
    "    dataframes = pd.concat(dataframes).reset_index(drop=True)\n",
    "    # display(dataframes)\n",
    "    feather.write_dataframe(dataframes, dest=f\"./nfb2023/{start[:7].replace('-','')}.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('./nfb2023')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VDID</th>\n",
       "      <th>RoadName</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>RoadDirection</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Occupancy</th>\n",
       "      <th>Volume</th>\n",
       "      <th>ActualLaneNum</th>\n",
       "      <th>LocationMile</th>\n",
       "      <th>DataCollectTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VD-N5-N-0.178-M-LOOP</td>\n",
       "      <td>國道5號</td>\n",
       "      <td>南港系統交流道</td>\n",
       "      <td>石碇交流道</td>\n",
       "      <td>N</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.178</td>\n",
       "      <td>2023-01-01 00:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VD-N5-N-0.706-M-LOOP</td>\n",
       "      <td>國道5號</td>\n",
       "      <td>南港系統交流道</td>\n",
       "      <td>石碇交流道</td>\n",
       "      <td>N</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.706</td>\n",
       "      <td>2023-01-01 00:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VD-N5-N-1.068-M-LOOP</td>\n",
       "      <td>國道5號</td>\n",
       "      <td>南港系統交流道</td>\n",
       "      <td>石碇交流道</td>\n",
       "      <td>N</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>-99.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.068</td>\n",
       "      <td>2023-01-01 00:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VD-N5-N-2.068-M-PS-LOOP</td>\n",
       "      <td>國道5號</td>\n",
       "      <td>南港系統交流道</td>\n",
       "      <td>石碇交流道</td>\n",
       "      <td>N</td>\n",
       "      <td>94.6000</td>\n",
       "      <td>4.1000</td>\n",
       "      <td>5.3000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.068</td>\n",
       "      <td>2023-01-01 00:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VD-N5-N-3.198-M-LOOP</td>\n",
       "      <td>國道5號</td>\n",
       "      <td>南港系統交流道</td>\n",
       "      <td>石碇交流道</td>\n",
       "      <td>N</td>\n",
       "      <td>90.8000</td>\n",
       "      <td>4.8000</td>\n",
       "      <td>5.1000</td>\n",
       "      <td>2</td>\n",
       "      <td>3.198</td>\n",
       "      <td>2023-01-01 00:04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819329</th>\n",
       "      <td>VD-N5-S-41.298-M-LOOP</td>\n",
       "      <td>國道5號</td>\n",
       "      <td>宜蘭交流道</td>\n",
       "      <td>羅東交流道</td>\n",
       "      <td>S</td>\n",
       "      <td>92.5000</td>\n",
       "      <td>1.6667</td>\n",
       "      <td>2.6667</td>\n",
       "      <td>2</td>\n",
       "      <td>41.298</td>\n",
       "      <td>2023-12-31 23:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819330</th>\n",
       "      <td>VD-N5-S-44.202-M-LOOP</td>\n",
       "      <td>國道5號</td>\n",
       "      <td>宜蘭交流道</td>\n",
       "      <td>羅東交流道</td>\n",
       "      <td>S</td>\n",
       "      <td>84.3333</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>3.3333</td>\n",
       "      <td>2</td>\n",
       "      <td>44.202</td>\n",
       "      <td>2023-12-31 23:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819331</th>\n",
       "      <td>VD-N5-S-46.566-M-LOOP</td>\n",
       "      <td>國道5號</td>\n",
       "      <td>宜蘭交流道</td>\n",
       "      <td>羅東交流道</td>\n",
       "      <td>S</td>\n",
       "      <td>65.8333</td>\n",
       "      <td>1.8333</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>2</td>\n",
       "      <td>46.566</td>\n",
       "      <td>2023-12-31 23:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819332</th>\n",
       "      <td>VD-N5-S-48.040-M-LOOP</td>\n",
       "      <td>國道5號</td>\n",
       "      <td>羅東交流道</td>\n",
       "      <td>蘇澳交流道</td>\n",
       "      <td>S</td>\n",
       "      <td>62.6667</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>48.040</td>\n",
       "      <td>2023-12-31 23:57:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9819333</th>\n",
       "      <td>VD-N5-S-53.110-M-LOOP</td>\n",
       "      <td>國道5號</td>\n",
       "      <td>羅東交流道</td>\n",
       "      <td>蘇澳交流道</td>\n",
       "      <td>S</td>\n",
       "      <td>79.1667</td>\n",
       "      <td>1.5000</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>2</td>\n",
       "      <td>53.110</td>\n",
       "      <td>2023-12-31 23:57:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9819334 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            VDID RoadName    Start    End RoadDirection  \\\n",
       "0           VD-N5-N-0.178-M-LOOP     國道5號  南港系統交流道  石碇交流道             N   \n",
       "1           VD-N5-N-0.706-M-LOOP     國道5號  南港系統交流道  石碇交流道             N   \n",
       "2           VD-N5-N-1.068-M-LOOP     國道5號  南港系統交流道  石碇交流道             N   \n",
       "3        VD-N5-N-2.068-M-PS-LOOP     國道5號  南港系統交流道  石碇交流道             N   \n",
       "4           VD-N5-N-3.198-M-LOOP     國道5號  南港系統交流道  石碇交流道             N   \n",
       "...                          ...      ...      ...    ...           ...   \n",
       "9819329    VD-N5-S-41.298-M-LOOP     國道5號    宜蘭交流道  羅東交流道             S   \n",
       "9819330    VD-N5-S-44.202-M-LOOP     國道5號    宜蘭交流道  羅東交流道             S   \n",
       "9819331    VD-N5-S-46.566-M-LOOP     國道5號    宜蘭交流道  羅東交流道             S   \n",
       "9819332    VD-N5-S-48.040-M-LOOP     國道5號    羅東交流道  蘇澳交流道             S   \n",
       "9819333    VD-N5-S-53.110-M-LOOP     國道5號    羅東交流道  蘇澳交流道             S   \n",
       "\n",
       "           Speed  Occupancy   Volume  ActualLaneNum  LocationMile  \\\n",
       "0       -99.0000   -99.0000 -99.0000              2         0.178   \n",
       "1       -99.0000   -99.0000 -99.0000              2         0.706   \n",
       "2       -99.0000   -99.0000 -99.0000              2         1.068   \n",
       "3        94.6000     4.1000   5.3000              2         2.068   \n",
       "4        90.8000     4.8000   5.1000              2         3.198   \n",
       "...          ...        ...      ...            ...           ...   \n",
       "9819329  92.5000     1.6667   2.6667              2        41.298   \n",
       "9819330  84.3333     2.3333   3.3333              2        44.202   \n",
       "9819331  65.8333     1.8333   1.5000              2        46.566   \n",
       "9819332  62.6667     0.6667   1.0000              2        48.040   \n",
       "9819333  79.1667     1.5000   2.0000              2        53.110   \n",
       "\n",
       "            DataCollectTime  \n",
       "0       2023-01-01 00:04:00  \n",
       "1       2023-01-01 00:04:00  \n",
       "2       2023-01-01 00:04:00  \n",
       "3       2023-01-01 00:04:00  \n",
       "4       2023-01-01 00:04:00  \n",
       "...                     ...  \n",
       "9819329 2023-12-31 23:57:00  \n",
       "9819330 2023-12-31 23:57:00  \n",
       "9819331 2023-12-31 23:57:00  \n",
       "9819332 2023-12-31 23:57:00  \n",
       "9819333 2023-12-31 23:57:00  \n",
       "\n",
       "[9819334 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = []\n",
    "for filename in os.listdir('./nfb2023'):\n",
    "    monthlyDf = feather.read_dataframe(f\"./nfb2023/{filename}\")\n",
    "    if (len(df) == 0):\n",
    "        df.append(monthlyDf)\n",
    "    else:\n",
    "        currDf = pd.concat(df).reset_index(drop=True)\n",
    "        monthlyDf = monthlyDf.loc[monthlyDf['VDID'].isin(set(currDf['VDID']))]\n",
    "        df.append(monthlyDf)\n",
    "df = pd.concat(df).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./df.csv', index=False, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: main\n",
    "# if __name__ == '__main__':\n",
    "#     # # read feather files to get dataframes\n",
    "#     # startDate = '2023-01-01'\n",
    "#     # endDate = getEndDate(startDate, days=10)\n",
    "#     # # df = getRollingMean(startDate, endDate)\n",
    "#     # df = feather.read_dataframe('./20230101-20230110.feather').sort_values(by=['RoadDirection','DataCollectTime','LocationMile']).reset_index(drop=True)\n",
    "    \n",
    "#     # Northbound data\n",
    "#     northDf = df.loc[df['RoadDirection']=='N'].reset_index(drop=True)\n",
    "#     each = 3\n",
    "#     vdGroups = groupVDs(northDf, each)    \n",
    "#     speedDataset, volDataset, occDataset = [], [], []\n",
    "#     for groupKey in vdGroups.keys():\n",
    "#         speeds, vols, occs = genSamples(northDf, vdGroups, groupKey, each, timeWindow=30)\n",
    "#         speedDataset.append(speeds)\n",
    "#         volDataset.append(vols)\n",
    "#         occDataset.append(occs)\n",
    "\n",
    "#     # Southbound data\n",
    "#     southDf = df.loc[df['RoadDirection']=='S'].reset_index(drop=True)\n",
    "#     each = 3\n",
    "#     vdGroups = groupVDs(southDf, each)    \n",
    "#     speedDataset, volDataset, occDataset = [], [], []\n",
    "#     for groupKey in vdGroups.keys():\n",
    "#         speeds, vols, occs = genSamples(southDf, vdGroups, groupKey, each, timeWindow=30)\n",
    "#         speedDataset.append(speeds)\n",
    "#         volDataset.append(vols)\n",
    "#         occDataset.append(occs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test cell for missing data\n",
    "# This part is genSamples()\n",
    "each = 3\n",
    "timeWindow = 30\n",
    "\n",
    "# df = feather.read_dataframe(\"./nfb2023/202305.feather\")\n",
    "northDf = df.loc[df['RoadDirection']=='N'].reset_index(drop=True)\n",
    "vdGroups = groupVDs(northDf, each)\n",
    "groupKey = 'VD-N5-N-1.068-M-LOOP'\n",
    "\n",
    "\n",
    "\n",
    "speeds, vols, occs = [], [], []\n",
    "tmpDf = df.loc[(df['VDID'].isin(vdGroups[f\"{groupKey}\"]))].sort_values(by=['LocationMile', 'DataCollectTime'])\n",
    "\n",
    "indices = [x for x in range(0, tmpDf.shape[0]+1, tmpDf.shape[0]//each)]\n",
    "mileMatx = np.zeros((each, tmpDf.shape[0]//each))\n",
    "speedMatx = np.zeros((each, tmpDf.shape[0]//each))\n",
    "volMatx = np.zeros((each, tmpDf.shape[0]//each))\n",
    "occMatx = np.zeros((each, tmpDf.shape[0]//each))\n",
    "for i, j, k in zip(range(each), indices[:-1], indices[1:]):\n",
    "    mileMatx[i] += tmpDf.iloc[j:k,:]['LocationMile'].to_numpy()\n",
    "    speedMatx[i] += tmpDf.iloc[j:k,:]['Speed'].to_numpy()\n",
    "    volMatx[i] += tmpDf.iloc[j:k,:]['Volume'].to_numpy()\n",
    "    occMatx[i] += tmpDf.iloc[j:k,:]['Occupancy'].to_numpy()\n",
    "\n",
    "# sliceLen = int((timeWindow / 5) + 1)\n",
    "# for x in range(speedMatx.shape[1]//sliceLen*sliceLen-(sliceLen-1)):\n",
    "#     speeds.append((speedMatx[:,x:x+sliceLen][:,:-1], speedMatx[:,x:x+sliceLen][:,[-1]]))\n",
    "#     vols.append((volMatx[:,x:x+sliceLen][:,:-1], volMatx[:,x:x+sliceLen][:,[-1]]))\n",
    "#     occs.append((occMatx[:,x:x+sliceLen][:,:-1], occMatx[:,x:x+sliceLen][:,[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mileMatx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf['LocationMile'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDf = northDf.sort_values(by=['LocationMile', 'DataCollectTime'])\n",
    "n = testDf['LocationMile'].nunique()\n",
    "\n",
    "indices__ = [x for x in range(0, testDf.shape[0]+1, testDf.shape[0]//n)]\n",
    "mileMatx__ = np.zeros((n, testDf.shape[0]//n))\n",
    "speedMatx__ = np.zeros((n, testDf.shape[0]//n))\n",
    "volMatx__ = np.zeros((n, testDf.shape[0]//n))\n",
    "occMatx__ = np.zeros((n, testDf.shape[0]//n))\n",
    "for i, j, k in zip(range(n), indices__[:-1], indices__[1:]):\n",
    "    mileMatx__[i] += testDf.iloc[j:k,:]['LocationMile'].to_numpy()\n",
    "    speedMatx__[i] += testDf.iloc[j:k,:]['Speed'].to_numpy()\n",
    "    volMatx__[i] += testDf.iloc[j:k,:]['Volume'].to_numpy()\n",
    "    occMatx__[i] += testDf.iloc[j:k,:]['Occupancy'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mileMatx__[:5,:5].copy()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m - np.ones(m.shape) * m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedMatx__[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volMatx__[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speedMatx[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volMatx[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occMatx[:,:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset for CNN (Short-term Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EACH = 3\n",
    "speedCollection, volCollection, occCollection = [], [], []\n",
    "\n",
    "# Northbound data\n",
    "northDf = df.loc[df['RoadDirection']=='N'].reset_index(drop=True)\n",
    "print(f\"northDf start grouping: {datetime.strftime(datetime.now(), '%Y-%m-%d %H:%M:%S')}\")\n",
    "northVDGrps = groupVDs(northDf, each=EACH)\n",
    "print(f\"northDf end grouping: {datetime.strftime(datetime.now(), '%Y-%m-%d %H:%M:%S')}\")\n",
    "for groupKey in northVDGrps.keys():\n",
    "    print(groupKey)\n",
    "    speeds, vols, occs = genSamples(northDf, northVDGrps, groupKey, each=EACH, timeWindow=30)\n",
    "    speedCollection += speeds\n",
    "    volCollection += vols\n",
    "    occCollection += occs\n",
    "\n",
    "# Southbound data\n",
    "southDf = df.loc[df['RoadDirection']=='S'].reset_index(drop=True)\n",
    "print(f\"southDf start grouping: {datetime.strftime(datetime.now(), '%Y-%m-%d %H:%M:%S')}\")\n",
    "southVDGrps = groupVDs(southDf, each=EACH)\n",
    "print(f\"southDf end grouping: {datetime.strftime(datetime.now(), '%Y-%m-%d %H:%M:%S')}\")\n",
    "# speedDataset, volDataset, occDataset = [], [], []\n",
    "for groupKey in southVDGrps.keys():\n",
    "    print(groupKey)\n",
    "    speeds, vols, occs = genSamples(southDf, southVDGrps, groupKey, each=EACH, timeWindow=30)\n",
    "    speedCollection += speeds\n",
    "    volCollection += vols\n",
    "    occCollection += occs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNDataset(Dataset):\n",
    "    def __init__(self, speedCollection, volCollection) -> None:\n",
    "        self.speedFeature = [speedCollection[x][0] for x in range(len(speedCollection))]\n",
    "        self.volFeature = [volCollection[x][0] for x in range(len(volCollection))]\n",
    "        self.speedLabels = [speedCollection[x][1][[1],:] for x in range(len(speedCollection))]\n",
    "        self.volLabels = [volCollection[x][1][[1],:] for x in range(len(volCollection))]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.speedFeature)\n",
    "    \n",
    "    def __getitem__(self, idx) -> torch.Tensor:\n",
    "        f1 = torch.tensor(self.speedFeature[idx], dtype=torch.float).unsqueeze(0).unsqueeze(0)\n",
    "        f2 = torch.tensor(self.volFeature[idx], dtype=torch.float).unsqueeze(0).unsqueeze(0)\n",
    "        l1 = torch.tensor(self.speedLabels[idx], dtype=torch.float).unsqueeze(0)\n",
    "        l2 = torch.tensor(self.volLabels[idx], dtype=torch.float).unsqueeze(0)\n",
    "        feature = torch.concat([f1, f2], dim=1)\n",
    "        label = torch.concat([l1, l2], dim=1)\n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSpeed, trainVol, testSpeed, testVol =\\\n",
    "    train_test_split(speedCollection, volCollection, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = CNNDataset(trainSpeed, trainVol)\n",
    "testDataset = CNNDataset(testSpeed, testVol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "route-plan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
